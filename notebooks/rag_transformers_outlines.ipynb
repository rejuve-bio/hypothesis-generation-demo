{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T21:41:49.380308Z",
     "start_time": "2024-06-13T21:41:49.371994Z"
    }
   },
   "source": [
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import List, Optional\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "from datasets import Features, Sequence, Value, load_dataset\n",
    "\n",
    "from transformers import (\n",
    "    DPRContextEncoder,\n",
    "    DPRContextEncoderTokenizerFast,\n",
    "    HfArgumentParser,\n",
    "    RagRetriever,\n",
    "    RagSequenceForGeneration,\n",
    "    RagTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:41:50.448376Z",
     "start_time": "2024-06-13T21:41:50.437492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text(text: str, n=100, character=\" \") -> List[str]:\n",
    "    \"\"\"Split the text every ``n``-th occurrence of ``character``\"\"\"\n",
    "    text = text.split(character)\n",
    "    return [character.join(text[i : i + n]).strip() for i in range(0, len(text), n)]\n",
    "\n",
    "def split_documents(documents: dict) -> dict:\n",
    "    \"\"\"Split documents into passages\"\"\"\n",
    "    titles, texts = [], []\n",
    "    for title, text in zip(documents[\"title\"], documents[\"text\"]):\n",
    "        if text is not None:\n",
    "            for passage in split_text(text):\n",
    "                titles.append(title if title is not None else \"\")\n",
    "                texts.append(passage)\n",
    "    return {\"title\": titles, \"text\": texts}\n",
    "\n",
    "\n",
    "# def embed(documents: dict, ctx_encoder: DPRContextEncoder, ctx_tokenizer: DPRContextEncoderTokenizerFast) -> dict:\n",
    "#     \"\"\"Compute the DPR embeddings of document passages\"\"\"\n",
    "#     input_ids = ctx_tokenizer(\n",
    "#         documents[\"title\"], documents[\"text\"], truncation=True, padding=\"longest\", return_tensors=\"pt\"\n",
    "#     )[\"input_ids\"]\n",
    "#     embeddings = ctx_encoder(input_ids.to(device=device), return_dict=True).pooler_output\n",
    "#     return {\"embeddings\": embeddings.detach().cpu().numpy()}"
   ],
   "id": "75325e2017f89a3c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:41:52.130670Z",
     "start_time": "2024-06-13T21:41:51.432541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"csv\", data_files=[\"../data/my_knowledge_dataset.csv\"], split=\"train\", \n",
    "                       delimiter=\"\\t\", column_names=[\"title\", \"text\"])\n",
    "# Then split the documents into passages of 100 words\n",
    "dataset = dataset.map(split_documents, batched=True)"
   ],
   "id": "7d46ee8e5cd8297e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Embed the Context Dataset",
   "id": "4a150975e501e97b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:41:52.326058Z",
     "start_time": "2024-06-13T21:41:52.320782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dpr_ctx_encoder_model_name = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
    "# ctx_encoder = DPRContextEncoder.from_pretrained(dpr_ctx_encoder_model_name).to(device=device)\n",
    "# ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(dpr_ctx_encoder_model_name)\n",
    "# new_features = Features(\n",
    "#     {\"text\": Value(\"string\"), \"title\": Value(\"string\"), \"embeddings\": Sequence(Value(\"float32\"))}\n",
    "# )  # optional, save as float32 instead of float64 to save space\n",
    "# dataset = dataset.map(\n",
    "#     partial(embed, ctx_encoder=ctx_encoder, ctx_tokenizer=ctx_tokenizer),\n",
    "#     batched=True,\n",
    "#     batch_size=16,\n",
    "#     features=new_features,\n",
    "# )"
   ],
   "id": "44f7e4e6e030fd78",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:42:07.845245Z",
     "start_time": "2024-06-13T21:41:52.983307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "dim = 768\n",
    "ST = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dim)"
   ],
   "id": "13aa2bf46a1df6c9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdu/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:42:07.850779Z",
     "start_time": "2024-06-13T21:42:07.847185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def embed(batch):\n",
    "    \"\"\"\n",
    "    adds a column to the dataset called 'embeddings'\n",
    "    \"\"\"\n",
    "    # or you can combine multiple columns here\n",
    "    # For example the title and the text\n",
    "    combined_text = []\n",
    "    for title, text in zip(batch['title'], batch['text']):\n",
    "        combined_text.append(' [SEP] '.join([title, text]))\n",
    "    print(combined_text)\n",
    "    return {\"embeddings\" : ST.encode(combined_text)}"
   ],
   "id": "3292f3214441c856",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:42:12.019360Z",
     "start_time": "2024-06-13T21:42:07.853346Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.map(embed, batched=True, batch_size=16)",
   "id": "21485aa994716135",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Index the dataset",
   "id": "b00228933187b8d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:42:12.168111Z",
     "start_time": "2024-06-13T21:42:12.022721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index = faiss.IndexHNSWFlat(dim, 128, faiss.METRIC_INNER_PRODUCT)\n",
    "dataset.add_faiss_index(\"embeddings\")"
   ],
   "id": "7fd8f1ef36553717",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c2124123e3a42818c624c223b0904c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'text', 'embeddings'],\n",
       "    num_rows: 6\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load RAG ",
   "id": "d2d8ccb937e3887f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:42:28.783438Z",
     "start_time": "2024-06-13T21:42:28.776899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(query: str, k: int = 3):\n",
    "    \"\"\"a function that embeds a new query and returns the most probable results\"\"\"\n",
    "    embedded_query = ST.encode(query) # embed new query\n",
    "    scores, retrieved_examples = dataset.get_nearest_examples( # retrieve results\n",
    "        \"embeddings\", embedded_query, # compare our new embedded query with the dataset embeddings\n",
    "        k=k # get only top k results\n",
    "    )\n",
    "    return scores, retrieved_examples"
   ],
   "id": "ea3bd3a88119cd24",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:42:30.286695Z",
     "start_time": "2024-06-13T21:42:29.912858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores, results = search(\"snake\")\n",
    "for i in range(len(scores)):\n",
    "    print(f\"Score: {scores[i]}: Title: {results['title'][i]}, Text: {results['text'][i]}\")"
   ],
   "id": "cef7f70b3bbda00c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 189.9427490234375: Title: Aaron, Text: his rod turn into a snake. Then he stretched out his rod in order to bring on the first three plagues. After that, Moses tended to act and speak for himself. During the journey in the wilderness, Aaron was not always prominent or active. At the battle with Amalek, he was chosen with Hur to support the hand of Moses that held the \"rod of God\". When the revelation was given to Moses at biblical Mount Sinai, he headed the elders of Israel who accompanied Moses on the way to the summit.\n",
      "Score: 245.70132446289062: Title: Aaron, Text: God at Sinai granted Aaron the priesthood for himself and his male descendants, and he became the first High Priest of the Israelites. Aaron died before the Israelites crossed the North Jordan river and he was buried on Mount Hor (Numbers 33:39; Deuteronomy 10:6 says he died and was buried at Moserah). Aaron is also mentioned in the New Testament of the Bible. According to the Book of Exodus, Aaron first functioned as Moses' assistant. Because Moses complained that he could not speak well, God appointed Aaron as Moses' \"prophet\" (Exodus 4:10-17; 7:1). At the command of Moses, he let\n",
      "Score: 246.78457641601562: Title: Aaron, Text: Aaron Aaron ( or ; \"Ahärôn\") is a prophet, high priest, and the brother of Moses in the Abrahamic religions. Knowledge of Aaron, along with his brother Moses, comes exclusively from religious texts, such as the Bible and Quran. The Hebrew Bible relates that, unlike Moses, who grew up in the Egyptian royal court, Aaron and his elder sister Miriam remained with their kinsmen in the eastern border-land of Egypt (Goshen). When Moses first confronted the Egyptian king about the Israelites, Aaron served as his brother's spokesman (\"prophet\") to the Pharaoh. Part of the Law (Torah) that Moses received from\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-13T21:42:32.982655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "hf_token = os.environ[\"HF_TOKEN\"]\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "rag_model_name = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(rag_model_name, token=hf_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(rag_model_name, token=hf_token)"
   ],
   "id": "d776e0b7e848b28a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60ab5a2af5084f17a79785301cc5d625"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T21:41:12.731561Z",
     "start_time": "2024-06-13T21:41:12.581889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYS_PROMPT = \"\"\"You are an assistant for answering questions.\n",
    "You are given the extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"I do not know.\" Don't make up an answer.\"\"\"\n",
    "def format_prompt(prompt,retrieved_documents,k):\n",
    "    \"\"\"using the retrieved documents we will prompt the model to generate our responses\"\"\"\n",
    "    PROMPT = f\"Question:{prompt}\\nContext:\"\n",
    "    for idx in range(k) :\n",
    "        PROMPT+= f\"{retrieved_documents['text'][idx]}\\n\"\n",
    "    return PROMPT\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "def generate(formatted_prompt):\n",
    "    formatted_prompt = formatted_prompt[:2000] # to avoid GPU OOM\n",
    "    # messages = [{\"role\":\"system\",\"content\":SYS_PROMPT},{\"role\":\"user\",\"content\":formatted_prompt}]\n",
    "    # tell the model to generate\n",
    "    input_ids = tokenizer(formatted_prompt,\n",
    "        return_tensors=\"pt\")[\"input_ids\"]\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    return tokenizer.decode(response, skip_special_tokens=True)"
   ],
   "id": "c809bcfcf9f5a27f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 12\u001B[0m\n\u001B[1;32m      8\u001B[0m         PROMPT\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mretrieved_documents[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m][idx]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PROMPT\n\u001B[1;32m     11\u001B[0m terminators \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m---> 12\u001B[0m     \u001B[43mtokenizer\u001B[49m\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[1;32m     13\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39mconvert_tokens_to_ids(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|eot_id|>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m ]\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(formatted_prompt):\n\u001B[1;32m     17\u001B[0m     formatted_prompt \u001B[38;5;241m=\u001B[39m formatted_prompt[:\u001B[38;5;241m2000\u001B[39m] \u001B[38;5;66;03m# to avoid GPU OOM\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T16:06:34.371162Z",
     "start_time": "2024-06-13T16:06:34.365483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# question = \"What does Moses' rod turn into ?\"\n",
    "# input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
    "# generated = model.generate(input_ids)\n",
    "# generated_string = tokenizer.batch_decode(generated, skip_special_token=True)[0]\n",
    "# print(f\"Q: {question}\")\n",
    "# print(f\"A: {generated_string}\")"
   ],
   "id": "8fbb65cad65b5a21",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T16:10:02.785370Z",
     "start_time": "2024-06-13T16:09:06.319528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formatted_prompt = format_prompt(\"What does Moses' rod turn into ?\", results, 3)\n",
    "res = generate(formatted_prompt)\n",
    "print(res)"
   ],
   "id": "b0dbfe77775f59a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God at Mount Sinai was the instruction that Aaron was to be the first high priest of the Israelites. After the Exodus, Aaron and his sons performed the duties of the priesthood in the Tabernacle and later the Temple in Jerusalem.\n",
      "\n",
      "The answer is a snake. The question states that Moses' rod turns into a snake, and later in the text it is mentioned that Aaron let his rod turn into a snake at the command of Moses.\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T16:36:38.253912Z",
     "start_time": "2024-06-13T16:36:27.571855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, constr\n",
    "import outlines\n",
    "from outlines.models import Transformers\n",
    "import torch\n",
    "\n",
    "class Response(BaseModel):\n",
    "    answer: str\n",
    "    \n",
    "outlines_model = Transformers(model, tokenizer)\n",
    "generator = outlines.generate.json(outlines_model, Response)\n",
    "rng = torch.Generator(device=\"cuda\")\n",
    "rng.manual_seed(42)\n",
    "\n",
    "res = generator(formatted_prompt)\n",
    "print(repr(res))"
   ],
   "id": "a0b112a9b4bde088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(answer='snake')\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da5915d0a97bc718"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
